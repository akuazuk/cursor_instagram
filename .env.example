OUTPUT_DIR=output
DB_PATH=cache/instagram_apify.sqlite
TARGETS_FILE=targets.txt
APIFY_BASE_URL=https://api.apify.com

# ===== LLM (бесплатно, локально через Ollama) =====
# Установи Ollama и запусти: `ollama serve`
# Скачай модель: `ollama pull llama3.2:3b`
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2:3b

# LLM настройки (опционально)
# BASELINE_PROFILE=kravira.by   # с кем сравниваем всех (по умолчанию: kravira)
# LLM_CHUNK_SIZE=60            # постов в одном LLM запросе
# LLM_MAX_POSTS_PER_PROFILE=0  # 0 = все
# OLLAMA_TIMEOUT_SECONDS=240
# LLM_POLISH=0                 # 1 = доп. "редакторский" проход (медленнее)

# Период (упрощение): можно задать либо START_DATE/END_DATE, либо PERIOD
# START_DATE=2025-01-01
# END_DATE=2026-02-01   # end-exclusive; если не задано — берётся tomorrow (UTC)
# PERIOD=this-month      # this-month | last-month | last-30d

# Apify token (держите в `.env`, НЕ в `.env.example`)
APIFY_TOKEN=apify_api_...

# ===== Vectara (семантический поиск по постам; ключ хранить ТОЛЬКО в `.env`) =====
# VECTARA_BASE_URL=https://api.vectara.io
# VECTARA_CUSTOMER_ID=3183420327
# VECTARA_CORPUS_KEY=kravira_inst    # это именно corpus_key (см. List corpora API: GET /v2/corpora)
# VECTARA_API_KEY=zwt_...   # персональный ключ (НЕ коммитить)
